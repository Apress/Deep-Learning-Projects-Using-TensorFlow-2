{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "final image colorization works.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nTdwjUdYHoQ"
      },
      "source": [
        "# <center> Image Colorization Final"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrJeS1qlYHoU"
      },
      "source": [
        "#### Import Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmYQl1oXLcyS"
      },
      "source": [
        "Download data from: https://github.com/VinitaSilaparasetty/Image-Colorization-with-TensorFlow2-and-Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkKQb1g3YHoV"
      },
      "source": [
        "# Importing Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input, InputLayer, Conv2D,UpSampling2D,DepthwiseConv2D\n",
        "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Reshape, Flatten,LeakyReLU, Dropout,DepthwiseConv2D\n",
        "from tensorflow.keras.layers import Flatten,MaxPooling2D,Conv2DTranspose, AveragePooling2D\n",
        "from tensorflow.keras.applications.vgg16  import VGG16\n",
        "from tensorflow.keras.models import Model,Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import layers\n",
        "from PIL import Image\n",
        "from tensorflow.keras.utils import plot_model\n",
        "import cv2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCvzEdFvCHvV"
      },
      "source": [
        "#Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHke_HUjZEHl"
      },
      "source": [
        "ab = np.load('ab1.npy')\n",
        "gray = np.load('gray_scale.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFXG5FaSCQUk"
      },
      "source": [
        "#Prepare Gray Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ieua3i7yZNdD"
      },
      "source": [
        "def batch_prep(gray_img, batch_size = 100, prep_in = tf.keras.applications.vgg16.preprocess_input):\n",
        "    img = np.zeros((batch_size, 224, 224, 3))\n",
        "    for i in range(0, 3):\n",
        "        img[:batch_size, :, :,i] = gray_img[:batch_size]\n",
        "    return prep_in(img)\n",
        "\n",
        "img_in = batch_prep(gray, batch_size = 300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFL-zJY8CTHS"
      },
      "source": [
        "#Combine Colorful Images and Gray Images for Input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQEfHlenZRV4"
      },
      "source": [
        "def get_rbg(gray_imgs, ab_imgs, n = 10):\n",
        "    \n",
        "    #create an empty array to store images\n",
        "    img1 = np.zeros((n, 224, 224, 3))\n",
        "    \n",
        "    img1[:, :, :, 0] = gray_imgs[0:n:]\n",
        "    img1[:, :, :, 1:] = ab_imgs[0:n:]\n",
        "    \n",
        "    #convert all the images to type unit8\n",
        "    img1 = img1.astype(\"uint8\")\n",
        "    \n",
        "    #create a new empty array\n",
        "    imgs= []\n",
        "    \n",
        "    for i in range(0, n):\n",
        "        imgs.append(cv2.cvtColor(img1[i], cv2.COLOR_LAB2RGB))\n",
        "        \n",
        "    #convert the image matrix into a numpy array\n",
        "    imgs = np.array(imgs)\n",
        "    \n",
        "    return imgs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6h5xz-cGYlAA"
      },
      "source": [
        "img_out = tf.keras.applications.vgg16.preprocess_input(get_rbg(gray_imgs = gray, ab_imgs = ab, n = 300))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pc_IdHPRCyci"
      },
      "source": [
        "#Build Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjdIK4fjYHop"
      },
      "source": [
        "model6 = VGG16(weights='imagenet',include_top=False,input_shape=(224, 224, 3))\n",
        "model = Sequential()\n",
        "model.add(InputLayer(input_shape=(img_in.shape[1], img_in.shape[2], 3)))\n",
        "model.add(Model(inputs=model6.inputs, outputs=model6.layers[-10].output))\n",
        "model.add(UpSampling2D((2, 2)))\n",
        "model.add(UpSampling2D((2, 2)))\n",
        "model.add(DepthwiseConv2D(32, (2, 2), activation=tf.nn.relu, padding='same'))\n",
        "model.add(UpSampling2D((2, 2)))\n",
        "model.add(DepthwiseConv2D(32, (2, 2), activation=tf.nn.relu, padding='same'))\n",
        "model.add(layers.ReLU(0.3))\n",
        "model.add(layers.Dropout(0.4))\n",
        "model.add(UpSampling2D((2, 2)))\n",
        "model.add(UpSampling2D((2, 2)))\n",
        "model.add(DepthwiseConv2D(2, (2, 2), activation=tf.nn.relu, padding='same'))\n",
        "model.add(layers.ReLU(0.3))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(UpSampling2D((2, 2)))\n",
        "model.add(layers.ReLU(0.3))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(AveragePooling2D(pool_size = (2, 2)))\n",
        "model.add(layers.Dense(units=3))\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzMCkldDC736"
      },
      "source": [
        "# Set Model Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XsXar55aGMx"
      },
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.Adam(),loss = 'mse',metrics=tf.keras.metrics.Accuracy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPrJQR8ADZDN"
      },
      "source": [
        "#Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4CvOaV8aPCt"
      },
      "source": [
        "#if you encounter an OOM error, reduce the batch_size to 8\n",
        "model.fit(img_in, img_out, epochs =5, batch_size = 16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INZZ2KMyDru6"
      },
      "source": [
        "#Obtain Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61clinnIbqs_"
      },
      "source": [
        "prediction = model.predict(img_in)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4mC9VhQDuiP"
      },
      "source": [
        "#View Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsW6EGj_ldgV"
      },
      "source": [
        "#display the predicted image\n",
        "plt.imshow(prediction[29])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}