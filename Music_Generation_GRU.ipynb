{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Music_Generation_GRU.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"rW8ZJDNozEaJ"},"source":["# <center>Compose Music Using a GRU"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"NVzXBNSEzEaL"},"source":["### Import Libraries"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Ws0X-3p3zEaM","colab":{}},"source":["import tensorflow as tf\n","from music21 import converter, instrument, note, chord,stream\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import os\n","import random\n","from keras.layers.core import Dense, Activation, Flatten\n","from keras.layers import GRU,Convolution1D,Convolution2D, Flatten, Dropout, Dense\n","from keras import utils as np_utils\n","from tensorflow.keras import layers"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cOn4iZJew-_H","colab_type":"text"},"source":["### Create the file path to your folder"]},{"cell_type":"code","metadata":{"id":"wiFbIG1kw-_I","colab_type":"code","colab":{}},"source":["os.chdir(\"//Users//vinitasilaparasetty//Downloads//Project 1- GRU//Input//music_files\")#enter the file path from your system."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CWmOdkwHw-_M","colab_type":"text"},"source":["#### Declare and Initialize variables"]},{"cell_type":"code","metadata":{"id":"df5PPyC-w-_O","colab_type":"code","colab":{}},"source":["musical_note = []\n","offset = []\n","instrumentlist=[]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WwvO5Ijuw-_T","colab_type":"text"},"source":["### Load Data"]},{"cell_type":"code","metadata":{"id":"4nOu6KJBw-_W","colab_type":"code","colab":{}},"source":["filenames = random.sample(os.listdir('D:\\\\Proj\\\\vinita\\\\Project 1- GRU\\Input\\\\music_files\\\\'), 5) #Only 5 files are taken at random\n","musiclist = os.listdir('D:\\\\Proj\\\\vinita\\\\Project 1- GRU\\Input\\\\music_files\\\\')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Plh0eDUuw-_a","colab_type":"text"},"source":["### Feature Extraction"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"UzZvOIuEzEaZ","colab":{}},"source":["for file in filenames:\n","    matching = [s for s in musiclist if file.split('_')[0] in s]\n","    print(matching)\n","    r1 = matching[random.randint(1, len(matching))] \n","    string_midi = converter.parse(r1)\n","    parsednotes = None\n","    parts = instrument.partitionByInstrument(string_midi)\n","    instrumentlist.append(parts.parts[0].getInstrument().instrumentName)\n","    if parts: # file has instrument parts\n","        parsednotes = parts.parts[0].recurse()\n","    else: # file has flat notes\n","        parsednotes = string_midi.flat.notes\n","    for element in parsednotes: #detect offsets\n","        offset.append(element.offset)\n","        if isinstance(element, note.Note):\n","            musical_note.append(str(element.pitch))\n","        elif isinstance(element, chord.Chord):\n","            musical_note.append('.'.join(str(n) for n in element.normalOrder))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_f-aZFhww-_f","colab_type":"text"},"source":["### Exploratory Data Analysis (EDA)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"5fyOzCIozEam"},"source":["#### Number of instruments found in music files"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Qjr6PP2vzEac","colab":{}},"source":["pd.Series(instrumentlist).value_counts() "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z_ty4raGw-_m","colab_type":"text"},"source":["#### Number of notes and chords"]},{"cell_type":"code","metadata":{"id":"mANTx4tww-_n","colab_type":"code","colab":{}},"source":["pd.Series(musical_note).value_counts() "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dEXdEeMtw-_w","colab_type":"text"},"source":["#### Visualisation of offset in the music file"]},{"cell_type":"code","metadata":{"id":"jZ7XR5_aw-_y","colab_type":"code","colab":{}},"source":["offset = [float(item) for item in offset] \n","plt.plot(offset)\n","plt.show() # this shows that offset is normally started from 0 for each musical file"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"DiMKSIiLzEaW"},"source":["### Data Preperation"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"T5TbWKGCzEao","colab":{}},"source":["sequence_length = 100\n","\n","# Arranging notes and chords in ascending order\n","pitchcategory = sorted(set(item for item in musical_note))\n","\n","# One hot encoding\n","note_encoding = dict((note, number) for number, note in enumerate(pitchcategory))\n","model_input_original = []\n","model_output = []\n","\n","# Prepare input and output data for model\n","for i in range(0, len(musical_note) - sequence_length, 1):\n","    sequence_in = musical_note[i:i + sequence_length]\n","    sequence_out = musical_note[i + sequence_length]\n","    model_input_original.append([note_encoding[char] for char in sequence_in])\n","    model_output.append(note_encoding[sequence_out])\n","\n","n_patterns = len(model_input_original)\n","\n","# converting data for compatibility with GRU\n","model_input = np.reshape(model_input_original, (n_patterns, sequence_length, 1))\n","\n","# standardizing model input data\n","model_output = np_utils.to_categorical(model_output)\n","Len_Notes = model_output.shape[1]\n","model_input = model_input / float(Len_Notes)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"rcl1Xy8LzEaz"},"source":["### Structure of the Model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"MSud8RRAzEa0","colab":{}},"source":["model_GRU = tf.keras.models.Sequential()\n","model_GRU.add(layers.GRU(16,input_shape=(model_input.shape[1], model_input.shape[2]),return_sequences=True))\n","model_GRU.add(layers.Dropout(0.3))\n","model_GRU.add(layers.GRU(64, return_sequences=True))\n","model_GRU.add(layers.Dropout(0.3))\n","model_GRU.add(layers.GRU(64))\n","model_GRU.add(layers.Dense(16))\n","model_GRU.add(layers.Dropout(0.3))\n","model_GRU.add(layers.Dense(Len_Notes))\n","model_GRU.add(layers.Activation('softmax'))\n","model_GRU.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n","model_GRU.summary() #Displays model architecture"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"yY-YhzL9zEa3"},"source":["### Train Model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ettClNa9zEa4","colab":{}},"source":["# initializing data for model prediction\n","int_to_note = dict((number, note) for number, note in enumerate(pitchcategory))\n","pattern = model_input_original[0]\n","prediction_output = []\n","model_GRU.fit(model_input, model_output, epochs=30, batch_size=64)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"5_aqSLXxzEa7"},"source":["### Prediction"]},{"cell_type":"markdown","metadata":{"id":"y3i6rLJkw_AH","colab_type":"text"},"source":["### Generate Input Sequence"]},{"cell_type":"code","metadata":{"id":"GmivEvwuw_AJ","colab_type":"code","colab":{}},"source":["# generate 500 notes\n","\n","for note_index in range(500):\n","    prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n","    prediction_input = prediction_input / float(Len_Notes)\n","    prediction_GRU = model_GRU.predict(prediction_input, verbose=0)\n","    index_GRU = np.argmax(prediction_GRU)\n","    index = index_GRU\n","    result = int_to_note[index]\n","    prediction_output.append(result)\n","    pattern = np.append(pattern,index)\n","    pattern = pattern[1:len(pattern)]\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uA6xP8Kaw_AM","colab_type":"text"},"source":["### Data Preperation"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"u44ctv_AzEa9","colab":{}},"source":["# prepare notes , chords and offset seperately \n","offlen = len(offset)\n","DifferentialOffset = (max(offset)-min(offset))/len(offset)\n","offset2 = offset.copy()\n","output_notes = []\n","i = 0\n","offset = []\n","initial = 0\n","for i in range(len(offset2)):\n","    offset.append(initial)\n","    initial  = initial+DifferentialOffset\n","# Differentiate notes and chords\n","i=0\n","for pattern in prediction_output:\n","    if ('.' in pattern) or pattern.isdigit():\n","        notes_in_chord = pattern.split('.')\n","        notes = []\n","        for check_note in notes_in_chord:\n","            gen_note = note.Note(int(check_note))\n","            gen_note.storedInstrument = instrument.Guitar()\n","            notes.append(gen_note)\n","        gen_chord = chord.Chord(notes)\n","        gen_chord.offset = offset[i]\n","        output_notes.append(gen_chord)\n","    else:\n","        gen_note = note.Note(pattern)\n","        gen_note.offset = offset[i]\n","        gen_note.storedInstrument = instrument.Guitar()\n","        output_notes.append(gen_note)\n","    i=i+1"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"J4OIUHC8zEba"},"source":["### Create MIDI file"]},{"cell_type":"code","metadata":{"id":"PvRqscdhw_AZ","colab_type":"code","colab":{}},"source":["os.chdir('D:\\\\Proj\\\\vinita\\\\Project 1- GRU\\Output\\\\') #Specify file path to store the MIDI file.\n","midi_stream = stream.Stream(output_notes) #create stream\n","midi_stream.write('midi', fp='GRU_output.mid') #create MIDI file using stream "],"execution_count":0,"outputs":[]}]}