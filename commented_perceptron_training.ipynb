{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"commented_perceptron_training.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"c05P9g5WjizZ"},"source":["# <center>Classify Structured Data Using a Perceptron"]},{"cell_type":"markdown","metadata":{"id":"_4Hghzipea5-","colab_type":"text"},"source":["A simple classification example to understand how a perceptron works. In this example, we take a dataset and try to accurately predict if the input is 1 or 0."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"VxyBFc_kKazA"},"source":["### Import TensorFlow and Other Libraries"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9dEreb4QKizj","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","\n","import tensorflow as tf\n","\n","from tensorflow import feature_column #reformats structured data for ease in calculations\n","from tensorflow.keras import layers #to create the layer in the neural network.\n","from sklearn.model_selection import train_test_split #splits the data for us\n","\n","from sklearn.metrics import confusion_matrix #calculates the confusion matrix\n","from sklearn.metrics import accuracy_score #calculates the accuracy score\n","\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline \n","#so that plots remain within the cell"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NO07ldudea6F","colab_type":"text"},"source":["### Declare Parameters\n","\n","We take 2 features as the input."]},{"cell_type":"code","metadata":{"id":"K6RJN5GJea6G","colab_type":"code","colab":{}},"source":["Number_of_features=2\n","Number_of_units=1 #indicates number of neurons"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DXUMV9tAea6L","colab_type":"text"},"source":["### Declare the Weights and Bias"]},{"cell_type":"code","metadata":{"id":"ybQdsV5Yea6M","colab_type":"code","colab":{}},"source":["weight=tf.Variable(tf.zeros([Number_of_features,Number_of_units])) #initializing to zero\n","bias=tf.Variable(tf.zeros([Number_of_units]))#Initializing to zero"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aJXZCoLOea6P","colab_type":"text"},"source":["### Define the Perceptron Function\n","\n","In this function, we calculate the matrix multiplication for the input features and the weights. Then to this product, we add the bias. Next,we use the sigmoid function as the activation function. Finally, we return the output."]},{"cell_type":"code","metadata":{"id":"Yvnalt41ea6R","colab_type":"code","colab":{}},"source":["def perceptron(x):\n","    I=tf.add(tf.matmul(x,weight),bias)\n","    output=tf.sigmoid(I)\n","    return output"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ww7V_XAWea6V","colab_type":"text"},"source":["Define the loss function and the optimizer."]},{"cell_type":"code","metadata":{"id":"BHmP9dOSea6W","colab_type":"code","colab":{}},"source":["individual_loss=lambda: abs(tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=y,logits=perceptron(x))))\n","\n","\n","optimizer=tf.keras.optimizers.Adam(.01)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_plngHBNea6b","colab_type":"text"},"source":["### Read in the Data"]},{"cell_type":"code","metadata":{"id":"XlsX4TKpea6c","colab_type":"code","colab":{}},"source":["dataframe = pd.read_csv('data.csv')\n","dataframe.head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nV-EIsTHea6f","colab_type":"text"},"source":["### Visualization of Labels"]},{"cell_type":"code","metadata":{"id":"BJOt354Eea6g","colab_type":"code","colab":{}},"source":["plt.scatter(dataframe.x1,dataframe.x2,c=dataframe.label)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pdWHSmK1ea6k","colab_type":"text"},"source":["## Prepare Inputs"]},{"cell_type":"markdown","metadata":{"id":"C2NkQ1dPea6l","colab_type":"text"},"source":["Seperate the inputs and the labels from the dataset."]},{"cell_type":"code","metadata":{"id":"1ui16Soyea6m","colab_type":"code","colab":{}},"source":["x_input=dataframe[['x1','x2']].as_matrix()\n","y_label=dataframe[['label']].as_matrix()\n","\n","#View the input matrix\n","x_input"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lwgcI7p1ea6p","colab_type":"text"},"source":["### Initialize Variables"]},{"cell_type":"markdown","metadata":{"id":"IZYFRQX0ea6r","colab_type":"text"},"source":["Initialize variables using the dataframe objects 'x_input' and 'y_label'."]},{"cell_type":"code","metadata":{"id":"2q0-7NuWea6s","colab_type":"code","colab":{}},"source":["#Initialize the variable x\n","x=tf.Variable(x_input)\n","\n","#Change the datatype of x to 'float32'\n","x=tf.cast(x,tf.float32)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Nee1j48ea6w","colab_type":"code","colab":{}},"source":["#Create the variable y\n","y=tf.Variable(y_label)\n","\n","#Change the datatype of y to 'float32'\n","y=tf.cast(y,tf.float32)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y8EWSe5vea60","colab_type":"text"},"source":["## Train the model\n","For this example, we train the model for 1000 iterations. The loss is minimized in each iteration."]},{"cell_type":"code","metadata":{"id":"WcUII_98ea61","colab_type":"code","colab":{}},"source":["for i in range(1000):\n","    optimizer.minimize(individual_loss,[weight,bias])\n","   "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Hg_Mzb9aea68","colab_type":"text"},"source":["### New Values for Weights and Bias"]},{"cell_type":"code","metadata":{"id":"pXS1Dn-vea69","colab_type":"code","colab":{}},"source":["tf.print(weight,bias)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b4mM63q7ea7A","colab_type":"text"},"source":["### View the Final Loss"]},{"cell_type":"code","metadata":{"id":"sBmb6_Ebea7B","colab_type":"code","colab":{}},"source":["final_loss=tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=y,logits=perceptron(x)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"J6cNad_fea7E","colab_type":"code","colab":{}},"source":["tf.print(final_loss)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6v-Ic6snea7I","colab_type":"text"},"source":["## Prediction Using the Trained Model"]},{"cell_type":"code","metadata":{"id":"79X21KKxea7J","colab_type":"code","colab":{}},"source":["ypred=perceptron(x)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G2NYx0HQea7N","colab_type":"code","colab":{}},"source":["ypred=tf.round(ypred) #Round off the output value to 1 or 0, to make the comparison with the target easier."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V4cmblkNea7Q","colab_type":"text"},"source":["## Evaluate the Model"]},{"cell_type":"markdown","metadata":{"id":"4wZFWeqsea7R","colab_type":"text"},"source":["### Accuracy Score\n","It indicates the percentage of accuracy of the model, after comparing the predicted output with the target."]},{"cell_type":"code","metadata":{"id":"dVQR8NRYea7U","colab_type":"code","colab":{}},"source":["accuracy_score(y, ypred)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oy29Fccxea7X","colab_type":"text"},"source":["### Confusion Matrix\n","If the maximum number of observations fall within the diagonal of the matrix, and the rest of the values are zero, then the model is 100% accurate."]},{"cell_type":"code","metadata":{"id":"-SWHQkiMea7Y","colab_type":"code","colab":{}},"source":["confusion_matrix(y, ypred)"],"execution_count":0,"outputs":[]}]}