{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"LSTM_Sentiment_Analysis.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"LRJPq_9Bp407","colab_type":"text"},"source":["# <center> Sentiment Analysis"]},{"cell_type":"markdown","metadata":{"id":"MQCU5Xhzp40-","colab_type":"text"},"source":["### Import Libraries"]},{"cell_type":"code","metadata":{"id":"GPFwW0NDp41A","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","import re\n","import keras\n","from keras import Model\n","from tensorflow.keras.layers import Flatten,LSTM, Dense, Flatten, Embedding\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.models import Sequential\n","from keras_preprocessing.text import Tokenizer\n","from keras.initializers import glorot_uniform\n","from sklearn import model_selection"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XEMJPpCGp41E","colab_type":"text"},"source":["### Load Data"]},{"cell_type":"code","metadata":{"id":"NN1besMaCkVf","colab_type":"code","colab":{}},"source":["#Read in data\n","with open('train.csv', 'r') as file:\n","    text = file.readlines()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6K89sQ2W-mAa","colab_type":"code","colab":{}},"source":["#create empty dataframe\n","x_train = pd.DataFrame()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vqPqdtNTCLg6","colab_type":"code","colab":{}},"source":["# fill in dataframe\n","word=[]\n","label=[]\n","for n in text:\n","    n=n.split()\n","    label.append(1) if n[0] ==\"__label__2\" else label.append(0)\n","    word.append(\" \".join(n[1:]))\n","x_train['consumer_review'] = word\n","x_train['polarity_label'] = label"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"o9GS4oLTCyqk","colab_type":"code","colab":{}},"source":["#view dataframe\n","x_train"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9gY2AMMxp41J","colab_type":"text"},"source":["### Data Preparation"]},{"cell_type":"code","metadata":{"id":"re2e6vRXC8Vn","colab_type":"code","colab":{}},"source":["#use only 20% of data to avoid overloading your system.You can reduce or increase this number according to your convenience.\n","_, x_set,_, y_set = \\\n","    model_selection.train_test_split(x_train['consumer_review'], \n","                                     x_train['polarity_label'], test_size=0.02)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BGWzoAmtDIfE","colab_type":"code","colab":{}},"source":["#data cleaning function\n","def data_prep(in_tex):\n","    # Remove punctuations and numbers\n","    out_tex = re.sub('[^a-zA-Z]', ' ', in_tex)\n","    # Convert upper case to lower case\n","    out_tex=\"\".join(list(map(lambda x:x.lower(),out_tex)))\n","    # Remove single character\n","    out_tex= re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', out_tex)\n","    return out_tex"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xx4gBb7MDzYd","colab_type":"code","colab":{}},"source":["#create new list with clean data\n","text_set=[]\n","for reviews in list(x_set):\n","    text_set.append(data_prep(reviews))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"svKHN92sD6yE","colab_type":"code","colab":{}},"source":["x_train= pd.DataFrame()\n","x_train['consumer_review'] = text_set\n","x_train['polarity_label'] = list(y_set)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LIObH9aaFoP1","colab_type":"code","colab":{}},"source":["#split data into 70% train and 30% test\n","x_train, x_test, y_train, y_test = \\\n","    model_selection.train_test_split(x_train['consumer_review'], \n","                                     x_train['polarity_label'], test_size=0.30)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IJrP4dPxGDz3","colab_type":"code","colab":{}},"source":["#convert to array\n","x_train=np.array(x_train.values.tolist())\n","x_test=np.array(x_test.values.tolist())\n","y_train=np.array(y_train.values.tolist())\n","y_test=np.array(y_test.values.tolist())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YNTCogAJGOAl","colab_type":"code","colab":{}},"source":["#tokenizer\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(x_train)\n","word_index=tokenizer.word_index\n","total_size = len(word_index)+1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"77v-2_BapWOm","colab_type":"code","outputId":"4a2e44dc-a39d-4a54-b372-561444417719","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(total_size)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["22259\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"m4GceaPyPqce","colab_type":"code","colab":{}},"source":["#text to sequence\n","x_train = tokenizer.texts_to_sequences(x_train)\n","x_test = tokenizer.texts_to_sequences(x_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LjlhychnPywf","colab_type":"code","colab":{}},"source":["#add padding to ensure the same length\n","max_length = 100\n","x_train = pad_sequences(x_train, padding='post', maxlen=max_length)\n","x_test = pad_sequences(x_test, padding='post', maxlen=max_length)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JjiesduSp41U","colab_type":"text"},"source":["### Structure Model"]},{"cell_type":"code","metadata":{"id":"-xfy2DbuP1G-","colab_type":"code","colab":{}},"source":["#Create Model\n","model = Sequential()\n","model.add(Embedding(total_size, 20, input_length=max_length))\n","model.add(LSTM(32,dropout=0.2, recurrent_dropout=0.2))\n","model.add(Dense(1, activation='sigmoid'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uoT8KXbEQdj4","colab_type":"code","colab":{}},"source":["#compile\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n","print(model.summary())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R3x3E_rnp41b","colab_type":"text"},"source":["### Train Model"]},{"cell_type":"code","metadata":{"id":"FAioMkDCQpFO","colab_type":"code","colab":{}},"source":["model.fit(x_train, y_train, batch_size=128, epochs=5, verbose=1, validation_data=(x_test, y_test))\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PCcFK89cp41k","colab_type":"text"},"source":["### Save Model (Optional)"]},{"cell_type":"code","metadata":{"id":"Ap-tHAOCp41l","colab_type":"code","colab":{}},"source":["model.save(\"model.h5\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4w__QN4Jp41q","colab_type":"text"},"source":["### Load Model"]},{"cell_type":"code","metadata":{"id":"7PIT4QGVp41r","colab_type":"code","colab":{}},"source":["model = keras.models.load_model(\"model.h5\")"],"execution_count":0,"outputs":[]}]}